import json
import os
from datetime import datetime
import schedule
import time
from pytrends.request import TrendReq
import google.generativeai as genai

class TrendBlogSystem:
    def __init__(self):
        """
        êµ¬ê¸€ íŠ¸ë Œë“œ ê¸°ë°˜ ë¸”ë¡œê·¸ ìë™ ì‘ì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        """
        self.pytrends = TrendReq(hl='ko', tz=540)  # í•œêµ­ì–´, í•œêµ­ ì‹œê°„ëŒ€
        self.used_keywords_file = 'used_keywords.json'
        self.blog_posts_dir = 'blog_posts'
        self.log_file = 'system_log.txt'
        
        # Gemini API ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°)
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            # í˜¹ì‹œ GOOGLE_API_KEYë¡œ ì„¤ì •í–ˆì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ í™•ì¸
            api_key = os.getenv('GOOGLE_API_KEY')

        if api_key:
            genai.configure(api_key=api_key)
            # gemini-1.5-flashê°€ ì•ˆë  ê²½ìš° gemini-pro ì‚¬ìš©
            self.model = genai.GenerativeModel('gemini-flash-latest')
            self.client_ready = True
        else:
            self.client_ready = False
            print("ê²½ê³ : GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        # ì´ˆê¸°í™”: ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ìƒì„±
        if not os.path.exists(self.blog_posts_dir):
            os.makedirs(self.blog_posts_dir)
            
        if not os.path.exists(self.used_keywords_file):
            self._save_used_keywords([])

    def _log(self, message):
        """ë¡œê·¸ ë©”ì‹œì§€ ê¸°ë¡"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    
    def _load_used_keywords(self):
        """ì´ë¯¸ ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            with open(self.used_keywords_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self._log(f"í‚¤ì›Œë“œ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return []
    
    def _save_used_keywords(self, keywords):
        """ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ ì €ì¥"""
        try:
            with open(self.used_keywords_file, 'w', encoding='utf-8') as f:
                json.dump(keywords, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self._log(f"í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def get_trending_keywords(self, region='south_korea'):
        """
        êµ¬ê¸€ íŠ¸ë Œë“œì—ì„œ ì‹¤ì‹œê°„ ì¸ê¸° ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ê¸° (Playwright ì‚¬ìš©)
        """
        try:
            self._log("êµ¬ê¸€ íŠ¸ë Œë“œì—ì„œ ì¸ê¸° ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            
            keywords = []
            
            # 1. Playwrightë¡œ ì‹¤ì œ Google Trends í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
            try:
                self._log("Playwright import ì‹œë„ ì¤‘...")
                from playwright.sync_api import sync_playwright
                
                self._log("Playwrightë¡œ Google Trends í˜ì´ì§€ ì ‘ê·¼ ì¤‘...")
                
                with sync_playwright() as p:
                    browser = p.chromium.launch(headless=True)
                    page = browser.new_page()
                    
                    # Google Trends í˜ì´ì§€ ì ‘ì†
                    page.goto('https://trends.google.co.kr/trending?geo=KR&hours=4', timeout=30000)
                    
                    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                    page.wait_for_selector('tr[role="row"]', timeout=10000)
                    
                    # JavaScriptë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
                    keywords = page.evaluate('''() => {
                        const rows = document.querySelectorAll('tr[role="row"]');
                        const keywords = [];
                        rows.forEach(row => {
                            const cells = row.querySelectorAll('td');
                            if (cells.length >= 2) {
                                const keywordDiv = cells[1].querySelector('div');
                                if (keywordDiv) {
                                    keywords.push(keywordDiv.innerText.trim());
                                }
                            }
                        });
                        return keywords;
                    }''')
                    
                    browser.close()
                    
                    if keywords:
                        self._log(f"Playwrightë¡œ {len(keywords)}ê°œ í‚¤ì›Œë“œ íšë“")
                        return keywords
                        
            except Exception as playwright_error:
                import traceback
                self._log(f"Playwright íŠ¸ë Œë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {playwright_error}")
                self._log(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")

            # 2. RSS í”¼ë“œ ì‹œë„ (Fallback)
            try:
                import requests
                import xml.etree.ElementTree as ET
                
                rss_url = "https://trends.google.com/trends/trendingsearches/daily/rss?geo=KR"
                response = requests.get(rss_url, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                })
                
                if response.status_code == 200:
                    root = ET.fromstring(response.content)
                    for item in root.findall('.//item'):
                        title = item.find('title')
                        if title is not None:
                            keywords.append(title.text)
                    self._log(f"RSS í”¼ë“œì—ì„œ {len(keywords)}ê°œ í‚¤ì›Œë“œ íšë“")
                else:
                    self._log(f"RSS ìš”ì²­ ì‹¤íŒ¨: Status Code {response.status_code}")
            except Exception as rss_error:
                self._log(f"RSS íŠ¸ë Œë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {rss_error}")

            if keywords:
                return keywords

            # 3. Pytrends ì‹œë„ (Fallback)
            try:
                trending_searches = self.pytrends.trending_searches(pn='south_korea')
                keywords = trending_searches[0].tolist()
                self._log(f"Pytrendsì—ì„œ {len(keywords)}ê°œ í‚¤ì›Œë“œ íšë“")
            except Exception as py_error:
                self._log(f"Pytrends ì‹¤íŒ¨: {py_error}")

            if keywords:
                return keywords
            
            # 4. ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ë°˜í™˜
            self._log("ëª¨ë“  íŠ¸ë Œë“œ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return ['ìƒì„±í˜• AI', 'íŒŒì´ì¬ ìë™í™”', 'ì£¼ë§ ë‚ ì”¨', 'ìµœì‹  ì˜í™” ìˆœìœ„', 'ë§›ì§‘ ì¶”ì²œ']
        
        except Exception as e:
            self._log(f"íŠ¸ë Œë“œ ê°€ì ¸ì˜¤ê¸° ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return ['í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ']
    
    def fetch_google_news(self, keyword, max_news=3):
        """
        Google ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            list: [{'title': str, 'url': str, 'image': str, 'summary': str, 'source': str}, ...]
        """
        try:
            self._log(f"'{keyword}' ê´€ë ¨ Google ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
            
            from playwright.sync_api import sync_playwright
            import urllib.parse
            
            news_list = []
            
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                
                # Google ë‰´ìŠ¤ ê²€ìƒ‰
                search_url = f"https://www.google.com/search?q={urllib.parse.quote(keyword)}&tbm=nws&hl=ko"
                page.goto(search_url, timeout=30000)
                page.wait_for_timeout(2000)
                
                # ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
                news_data = page.evaluate('''() => {
                    const newsItems = [];
                    const articles = document.querySelectorAll('div.SoaBEf, div.WlydOe');
                    
                    for (let i = 0; i < Math.min(articles.length, 3); i++) {
                        const article = articles[i];
                        
                        // ì œëª©
                        const titleElem = article.querySelector('div[role="heading"]');
                        const title = titleElem ? titleElem.innerText : '';
                        
                        // URL
                        const linkElem = article.querySelector('a');
                        const url = linkElem ? linkElem.href : '';
                        
                        // ì´ë¯¸ì§€
                        const imgElem = article.querySelector('img');
                        const image = imgElem ? imgElem.src : '';
                        
                        // ìš”ì•½
                        const summaryElem = article.querySelector('div.GI74Re');
                        const summary = summaryElem ? summaryElem.innerText : '';
                        
                        // ì¶œì²˜ - ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„
                        let source = '';
                        
                        // ë°©ë²• 1: CEMjEf í´ë˜ìŠ¤
                        let sourceElem = article.querySelector('div.CEMjEf span');
                        if (sourceElem) {
                            source = sourceElem.innerText;
                        }
                        
                        // ë°©ë²• 2: MgUUmf í´ë˜ìŠ¤ (ë‰´ìŠ¤ ì¶œì²˜)
                        if (!source) {
                            sourceElem = article.querySelector('.MgUUmf.NUnG9d span');
                            if (sourceElem) source = sourceElem.innerText;
                        }
                        
                        // ë°©ë²• 3: URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
                        if (!source && url) {
                            try {
                                const urlObj = new URL(url);
                                source = urlObj.hostname.replace('www.', '');
                            } catch (e) {
                                source = '';
                            }
                        }
                        
                        if (title && url) {
                            newsItems.push({
                                title: title,
                                url: url,
                                image: image,
                                summary: summary || title,
                                source: source || 'Unknown Source'
                            });
                        }
                    }
                    
                    return newsItems;
                }''')
                
                browser.close()
                
                if news_data:
                    self._log(f"{len(news_data)}ê°œì˜ ë‰´ìŠ¤ í•­ëª© ë°œê²¬")
                    return news_data[:max_news]
                
        except Exception as e:
            self._log(f"Google ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
        return []
    
    def fetch_google_image(self, keyword):
        """
        Google ì´ë¯¸ì§€ ê²€ìƒ‰ì—ì„œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            str: ì´ë¯¸ì§€ URL ë˜ëŠ” None
        """
        try:
            self._log(f"'{keyword}' ê´€ë ¨ Google ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
            
            from playwright.sync_api import sync_playwright
            import urllib.parse
            
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                
                # Google ì´ë¯¸ì§€ ê²€ìƒ‰
                search_url = f"https://www.google.com/search?q={urllib.parse.quote(keyword)}&tbm=isch&hl=ko"
                page.goto(search_url, timeout=30000)
                page.wait_for_timeout(2000)
                
                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_url = page.evaluate('''() => {
                    const img = document.querySelector('img[data-src], img.rg_i');
                    if (img) {
                        return img.src || img.getAttribute('data-src');
                    }
                    return null;
                }''')
                
                browser.close()
                
                if image_url and image_url.startswith('http'):
                    self._log(f"ëŒ€í‘œ ì´ë¯¸ì§€ ë°œê²¬: {image_url[:50]}...")
                    return image_url
                
        except Exception as e:
            self._log(f"Google ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
        return None
    
    def select_keyword(self, keywords):
        """
        ì‚¬ìš©ë˜ì§€ ì•Šì€ ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ì„ íƒ
        
        Args:
            keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            str: ì„ íƒëœ í‚¤ì›Œë“œ ë˜ëŠ” None
        """
        used_keywords = self._load_used_keywords()
        
        for keyword in keywords:
            if keyword not in used_keywords:
                self._log(f"ì„ íƒëœ í‚¤ì›Œë“œ: {keyword}")
                return keyword
        
        self._log("ì‚¬ìš© ê°€ëŠ¥í•œ ìƒˆë¡œìš´ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    def generate_blog_content(self, keyword):
        """
        ì„ íƒëœ í‚¤ì›Œë“œë¡œ SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„±
        
        Args:
            keyword: ë¸”ë¡œê·¸ ì£¼ì œ í‚¤ì›Œë“œ
        
        Returns:
            str: ìƒì„±ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸  (HTML í˜•ì‹)
        """
        if not self.client_ready:
            return f"<h1>{keyword}ì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸</h1>\n\n<p>(API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹¤ì œ ì½˜í…ì¸ ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤)</p>"
        
        try:
            self._log(f"'{keyword}' í‚¤ì›Œë“œë¡œ ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„± ì¤‘...")
            
            # 1. Google ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            news_items = self.fetch_google_news(keyword, max_news=3)
            
            # 2. Google ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            featured_image = self.fetch_google_image(keyword)
            
            # 3. AIë¡œ ë³¸ë¬¸ ìƒì„±
            prompt = f"""
'{keyword}'ì— ëŒ€í•´ ì •ë³´ íƒìƒ‰ì„ í•˜ëŠ” ì‚¬ìš©ìëŠ”
ë‰´ìŠ¤ë‚˜ íŠ¸ë Œë“œ ìš”ì•½ì´ ì•„ë‹ˆë¼,
íŒë‹¨ ê¸°ì¤€ê³¼ êµ¬ì¡°ë¥¼ ì´í•´í•˜ê¸° ìœ„í•œ ê°œìš” ì •ë³´ë¥¼ ì›í•œë‹¤.

ì´ ê¸€ì€ ë°˜ë“œì‹œ 'front-matter + ë³¸ë¬¸'ì„ í•¨ê»˜ ìƒì„±í•´ì•¼ í•˜ë©°,
front-matterì˜ ì„±ê²©ì€ ë³¸ë¬¸ ë‚´ìš©ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•œë‹¤.

[Front-matter ì‘ì„± ê·œì¹™]
- title: '{keyword}' + íŒë‹¨/êµ¬ì¡°/ê¸°ì¤€/ë¶„ì„ ì¤‘ í•˜ë‚˜ë¥¼ í¬í•¨í•œ ì •ë³´í˜• ì œëª©
- categories: ë°˜ë“œì‹œ [ì •ë³´, ë¶„ì„] ì¤‘ì—ì„œë§Œ ì„ íƒ (íŠ¸ë Œë“œ ì‚¬ìš© ê¸ˆì§€)
- tags: ['{keyword}', íŒë‹¨ê¸°ì¤€, êµ¬ì¡°ë¶„ì„] í˜•íƒœë¡œ êµ¬ì„±
- description: '{keyword}'ì— ëŒ€í•´ íŒë‹¨ ê¸°ì¤€ê³¼ í•œê³„ë¥¼ ì •ë¦¬í•œ ì •ë³´ì„± ë¶„ì„ ê¸€
- 'ìµœì‹ ', 'íŠ¸ë Œë“œ', 'ë‰´ìŠ¤' ë‹¨ì–´ ì‚¬ìš© ê¸ˆì§€

[ê¸€ì˜ ëª©ì ]
- '{keyword}'ë¥¼ ì²˜ìŒ ì ‘í•˜ëŠ” ì‚¬ëŒì´
  ì´ ê°œë…ì´ë‚˜ ëŒ€ìƒì„ ì–´ë–»ê²Œ ë°”ë¼ë´ì•¼ í• ì§€
  íŒë‹¨ ê¸°ì¤€ì„ ì œê³µí•˜ëŠ” ì •ë³´ì„± ì½˜í…ì¸  ì‘ì„±

[ì‘ì„± ì›ì¹™]
- í™ë³´, ë§ˆì¼€íŒ…, ë‰´ìŠ¤ ìš”ì•½ì²˜ëŸ¼ ë³´ì´ì§€ ì•Šê²Œ ì‘ì„±
- ê°œì¸ ê²½í—˜, ì‹œì  íŠ¹ì •(ìµœê·¼, ìš”ì¦˜ ë“±) í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ì¼ë°˜ì ì¸ íŒë‹¨ ê¸°ì¤€ â†’ íŠ¹ì§• â†’ í•œê³„ êµ¬ì¡° ìœ ì§€

[í•„ìˆ˜ êµ¬ì„±]
1. ì„œë¡ : ì‚¬ëŒë“¤ì´ '{keyword}'ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì´ìœ  ìš”ì•½
2. ë³¸ë¬¸ 1: ì´ ì£¼ì œë¥¼ íŒë‹¨í•  ë•Œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ê¸°ì¤€ 2~3ê°€ì§€
3. ë³¸ë¬¸ 2: í•´ë‹¹ ê¸°ì¤€ì—ì„œ ë³¸ '{keyword}'ì˜ íŠ¹ì§•
4. ë³¸ë¬¸ 3: ìƒí™©ì´ë‚˜ ì¡°ê±´ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” í•œê³„ë‚˜ ì£¼ì˜ì 
5. ê²°ë¡ : ì–´ë–¤ ê²½ìš°ì— ì°¸ê³ í•˜ë©´ ì í•©í•œ ì •ë³´ì¸ì§€ ëª…í™•íˆ ì •ë¦¬

[ê²°ë¡  í•„ìˆ˜ ë¬¸ì¥]
- "ì´ ì •ë³´ëŠ” '{keyword}'ë¥¼ ì²˜ìŒ ì ‘í•˜ê±°ë‚˜,
   ê°œìš” ìˆ˜ì¤€ì—ì„œ íŒë‹¨ ê¸°ì¤€ì´ í•„ìš”í•œ ê²½ìš°ì— ì°¸ê³ í•˜ê¸° ì í•©í•˜ë‹¤."

[í˜•ì‹]
- Markdown
- front-matterëŠ” YAML í˜•ì‹ìœ¼ë¡œ ë³¸ë¬¸ ìµœìƒë‹¨ì— ì‘ì„±
- ì „ì²´ ë¶„ëŸ‰ 900~1200ì

ìœ„ ê¸°ì¤€ì„ ì–´ê¸°ì§€ ë§ê³  front-matterì™€ ë³¸ë¬¸ì„ í•¨ê»˜ ì‘ì„±í•˜ë¼.
"""

            
            response = self.model.generate_content(prompt)
            main_content = response.text
            
            # 4. Markdown ì½˜í…ì¸  ìƒì„± (Frontmatter í¬í•¨)
            markdown_content = self._build_markdown_content(keyword, main_content, news_items, featured_image)
            
            self._log("ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ")
            return markdown_content
        
        except Exception as e:
            self._log(f"ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def download_image(self, image_url, keyword, index=0):
        """
        ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ ì €ì¥
        
        Returns:
            str: ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” ì›ë³¸ URL
        """
        try:
            import requests
            import os
            from urllib.parse import urlparse
            
            # images ë””ë ‰í† ë¦¬ ìƒì„±
            images_dir = os.path.join(self.blog_posts_dir, 'images')
            if not os.path.exists(images_dir):
                os.makedirs(images_dir)
            
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            ext = '.jpg'  # ê¸°ë³¸ í™•ì¥ì
            filename = f"{timestamp}_{keyword}_{index}{ext}"
            filepath = os.path.join(images_dir, filename)
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = requests.get(image_url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if response.status_code == 200:
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                # ìƒëŒ€ ê²½ë¡œ ë°˜í™˜
                relative_path = f"images/{filename}"
                self._log(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {relative_path}")
                return relative_path
            
        except Exception as e:
            self._log(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return image_url  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ URL ë°˜í™˜
    
    def _build_markdown_content(self, keyword, main_content, news_items, featured_image):
        """
        Markdown ì½˜í…ì¸  ìƒì„± (Frontmatter í¬í•¨)
        """
        # ëŒ€í‘œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        local_featured_image = None
        if featured_image:
            local_featured_image = self.download_image(featured_image, keyword, 'featured')
        
        # ë‚ ì§œ ìƒì„±
        today = datetime.now().strftime('%Y-%m-%d')
        
        # AIê°€ ìƒì„±í•œ ë³¸ë¬¸ì—ì„œ Frontmatter ì²˜ë¦¬ ë° ëŒ€í‘œ ì´ë¯¸ì§€ ì‚½ì…
        markdown = ""
        
        # Frontmatter ë¶„ë¦¬ (---ë¡œ ì‹œì‘í•˜ê³  ---ë¡œ ëë‚˜ëŠ” ë¶€ë¶„ ì°¾ê¸°)
        if main_content.strip().startswith('---'):
            parts = main_content.split('---', 2)
            if len(parts) >= 3:
                # parts[0]ì€ ë¹ˆ ë¬¸ìì—´, parts[1]ì€ Frontmatter ë‚´ìš©, parts[2]ëŠ” ë³¸ë¬¸
                frontmatter = f"---{parts[1]}---\n\n"
                body = parts[2].strip()
                
                markdown += frontmatter
                
                # ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ê°€ (Frontmatter ì§í›„)
                if local_featured_image:
                    markdown += f"![{keyword}]({local_featured_image})\n\n"
                
                markdown += f"{body}\n\n"
            else:
                # Frontmatter í˜•ì‹ì´ ì´ìƒí•˜ë©´ ê·¸ëƒ¥ í•©ì¹˜ê¸°
                if local_featured_image:
                    markdown += f"![{keyword}]({local_featured_image})\n\n"
                markdown += f"{main_content}\n\n"
        else:
            # Frontmatterê°€ ì—†ëŠ” ê²½ìš° (ë§Œì•½ì„ ëŒ€ë¹„í•´)
            if local_featured_image:
                markdown += f"![{keyword}]({local_featured_image})\n\n"
            markdown += f"{main_content}\n\n"
        
        # ë‰´ìŠ¤ ì„¹ì…˜ ì¶”ê°€
        if news_items:
            markdown += "## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤\n\n"
            for idx, news in enumerate(news_items):
                # ë‰´ìŠ¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                news_image = news.get('image', '')
                if news_image and news_image.startswith('http'):
                    news_image = self.download_image(news_image, keyword, f'news_{idx}')
                
                markdown += f"### [{news['title']}]({news['url']})\n"
                markdown += f"* **ì¶œì²˜**: {news.get('source', 'Unknown Source')}\n"
                if news_image:
                    markdown += f"![ë‰´ìŠ¤ ì´ë¯¸ì§€]({news_image})\n"
                markdown += f"> {news['summary'][:150]}...\n\n"
                
        return markdown
        
        # ì „ì²´ HTML ë¬¸ì„œ
        html = f'''<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="{keyword}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”. íŠ¸ë Œë“œ ë¶„ì„ê³¼ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.">
    <meta name="keywords" content="{keyword}, íŠ¸ë Œë“œ, ë‰´ìŠ¤, ì •ë³´">
    <meta name="author" content="Trend Blog System">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="{keyword} - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„">
    <meta property="og:description" content="{keyword}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë‰´ìŠ¤">
    {f'<meta property="og:image" content="{featured_image}">' if featured_image else ''}
    
    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="{keyword} - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„">
    <meta name="twitter:description" content="{keyword}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë‰´ìŠ¤">
    {f'<meta name="twitter:image" content="{featured_image}">' if featured_image else ''}
    
    <title>{keyword} - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„</title>
    
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        
        .container {{
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        
        .featured-image {{
            width: 100%;
            max-height: 400px;
            object-fit: cover;
            border-radius: 8px;
            margin-bottom: 30px;
        }}
        
        h1 {{
            color: #1a1a1a;
            font-size: 2.5em;
            margin-bottom: 20px;
            line-height: 1.2;
        }}
        
        h2 {{
            color: #2c3e50;
            font-size: 1.8em;
            margin-top: 30px;
            margin-bottom: 15px;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }}
        
        h3 {{
            color: #34495e;
            font-size: 1.3em;
            margin-top: 20px;
        }}
        
        p {{
            margin-bottom: 15px;
            font-size: 1.1em;
        }}
        
        .news-section {{
            margin: 40px 0;
            padding: 30px;
            background-color: #f8f9fa;
            border-radius: 8px;
        }}
        
        .news-cards {{
            display: grid;
            gap: 20px;
            margin-top: 20px;
        }}
        
        .news-card {{
            display: flex;
            gap: 15px;
            background-color: white;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #3498db;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            transition: transform 0.2s, box-shadow 0.2s;
        }}
        
        .news-card:hover {{
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }}
        
        .news-image {{
            width: 120px;
            height: 120px;
            object-fit: cover;
            border-radius: 4px;
            flex-shrink: 0;
        }}
        
        .news-content {{
            flex: 1;
        }}
        
        .news-content h3 {{
            margin: 0 0 10px 0;
            font-size: 1.1em;
        }}
        
        .news-content h3 a {{
            color: #2c3e50;
            text-decoration: none;
        }}
        
        .news-content h3 a:hover {{
            color: #3498db;
            text-decoration: underline;
        }}
        
        .news-summary {{
            color: #666;
            font-size: 0.95em;
            margin: 0;
        }}
        
        strong {{
            color: #2c3e50;
            font-weight: 600;
        }}
        
        em {{
            color: #7f8c8d;
            font-style: italic;
        }}
        
        @media (max-width: 768px) {{
            .container {{
                padding: 20px;
            }}
            
            h1 {{
                font-size: 2em;
            }}
            
            .news-card {{
                flex-direction: column;
            }}
            
            .news-image {{
                width: 100%;
                height: 200px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        {featured_image_html}
        {news_cards_html}
        {main_content}
    </div>
</body>
</html>'''
        
        return html
    
    def save_blog_post(self, keyword, content):
        """
        ìƒì„±ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥
        
        Args:
            keyword: í‚¤ì›Œë“œ
            content: ë¸”ë¡œê·¸ ì½˜í…ì¸  (HTML)
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{timestamp}_{keyword}.md"
            filepath = os.path.join(self.blog_posts_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self._log(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            
            # ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ì— ì¶”ê°€
            used_keywords = self._load_used_keywords()
            used_keywords.append(keyword)
            self._save_used_keywords(used_keywords)
            
            return filepath
        
        except Exception as e:
            self._log(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            return None
    
    def run_blog_creation(self):
        """
        ì „ì²´ ë¸”ë¡œê·¸ ì‘ì„± í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        """
        self._log("=" * 50)
        self._log("ë¸”ë¡œê·¸ ì‘ì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        
        # 1. íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        keywords = self.get_trending_keywords()
        
        if not keywords:
            self._log("í‚¤ì›Œë“œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ì„ íƒ
        selected_keyword = self.select_keyword(keywords)
        
        if not selected_keyword:
            self._log("ëª¨ë“  í‚¤ì›Œë“œê°€ ì´ë¯¸ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        # 3. ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„±
        content = self.generate_blog_content(selected_keyword)
        
        if not content:
            self._log("ì½˜í…ì¸  ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # 4. ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥
        filepath = self.save_blog_post(selected_keyword, content)
        
        if filepath:
            self._log(f"ë¸”ë¡œê·¸ ì‘ì„± ì™„ë£Œ: {selected_keyword}")
        else:
            self._log("ë¸”ë¡œê·¸ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        self._log("ë¸”ë¡œê·¸ ì‘ì„± í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
        self._log("=" * 50)

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
    """
    system = TrendBlogSystem()
    
    # ìŠ¤ì¼€ì¤„ ì„¤ì •: ì˜¤ì „ 8ì‹œë¶€í„° 4ì‹œê°„ ê°„ê²©
    schedule.every().day.at("08:00").do(system.run_blog_creation)
    schedule.every().day.at("12:00").do(system.run_blog_creation)
    schedule.every().day.at("16:00").do(system.run_blog_creation)
    schedule.every().day.at("20:00").do(system.run_blog_creation)
    
    print("ë¸”ë¡œê·¸ ìë™ ì‘ì„± ì‹œìŠ¤í…œ ì‹œì‘")
    print("ìŠ¤ì¼€ì¤„: 08:00, 12:00, 16:00, 20:00")
    print("ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    
    # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
    system.run_blog_creation()
    
    # ìŠ¤ì¼€ì¤„ ë£¨í”„ ì‹¤í–‰
    while True:
        schedule.run_pending()
        time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

if __name__ == "__main__":
    main()