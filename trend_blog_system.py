import json
import os
from datetime import datetime
import schedule
import time
from pytrends.request import TrendReq
import google.generativeai as genai

class TrendBlogSystem:
    def __init__(self):
        """
        êµ¬ê¸€ íŠ¸ë Œë“œ ê¸°ë°˜ ë¸”ë¡œê·¸ ìë™ ì‘ì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        """
        self.pytrends = TrendReq(hl='ko', tz=540)  # í•œêµ­ì–´, í•œêµ­ ì‹œê°„ëŒ€
        self.used_keywords_file = 'used_keywords.json'
        self.config_file = 'system_config.json'
        self.blog_posts_dir = 'blog_posts'
        self.log_file = 'system_log.txt'
        
        # Gemini API ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°)
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            # í˜¹ì‹œ GOOGLE_API_KEYë¡œ ì„¤ì •í–ˆì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ í™•ì¸
            api_key = os.getenv('GOOGLE_API_KEY')

        if api_key:
            genai.configure(api_key=api_key)
            # gemini-1.5-flashê°€ ì•ˆë  ê²½ìš° gemini-pro ì‚¬ìš©
            self.model = genai.GenerativeModel('gemini-flash-latest')
            self.client_ready = True
        else:
            self.client_ready = False
            print("ê²½ê³ : GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        # ë¸”ë¡œê·¸ í˜ë¥´ì†Œë‚˜ ì„¤ì • (friendly, professional, analytical)
        self.persona = os.getenv('BLOG_PERSONA', 'friendly').lower()
        self._log(f"ë¸”ë¡œê·¸ í˜ë¥´ì†Œë‚˜ ì„¤ì •: {self.persona}")
        
        # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì„¤ì •
        self.tg_token = os.getenv('TELEGRAM_TOKEN', '').strip()
        self.tg_chat_id = os.getenv('TELEGRAM_CHAT_ID', '').strip()
        if self.tg_token and self.tg_chat_id:
            self._log("í…”ë ˆê·¸ë¨ ì•Œë¦¼ í™œì„±í™”ë¨")
            
        # ì´ˆê¸°í™”: ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ìƒì„±
        if not os.path.exists(self.blog_posts_dir):
            os.makedirs(self.blog_posts_dir)
            
        if not os.path.exists(self.used_keywords_file):
            self._save_used_keywords([])
            
        # ì„¤ì • ë¡œë“œ
        self.config = self._load_config()

    def _log(self, message):
        """ë¡œê·¸ ë©”ì‹œì§€ ê¸°ë¡"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
            
    def _send_telegram_notification(self, message):
        """í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡"""
        if not self.tg_token or not self.tg_chat_id:
            return
            
        try:
            import requests
            url = f"https://api.telegram.org/bot{self.tg_token}/sendMessage"
            data = {
                "chat_id": self.tg_chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }
            response = requests.post(url, data=data, timeout=10)
            response.raise_for_status()
        except Exception as e:
            error_details = f"{e}"
            if 'response' in locals():
                error_details += f" (ì‘ë‹µ: {response.text})"
            self._log(f"í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {error_details}")
    
    def _load_used_keywords(self):
        """ì´ë¯¸ ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            with open(self.used_keywords_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self._log(f"í‚¤ì›Œë“œ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return []
    
    def _save_used_keywords(self, keywords):
        """ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ ì €ì¥"""
        try:
            with open(self.used_keywords_file, 'w', encoding='utf-8') as f:
                json.dump(keywords, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self._log(f"í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

    def _load_config(self):
        """ì‹œìŠ¤í…œ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°"""
        default_config = {
            "publication_times": ["08:00", "12:00", "16:00", "20:00"]
        }
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                self._save_config(default_config)
                return default_config
        except Exception as e:
            self._log(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return default_config

    def _save_config(self, config):
        """ì‹œìŠ¤í…œ ì„¤ì • ì €ì¥"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self._log(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def get_trending_keywords(self, region='south_korea'):
        """
        êµ¬ê¸€ íŠ¸ë Œë“œì—ì„œ ì‹¤ì‹œê°„ ì¸ê¸° ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ê¸° (Playwright ì‚¬ìš©)
        """
        try:
            self._log("êµ¬ê¸€ íŠ¸ë Œë“œì—ì„œ ì¸ê¸° ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            
            keywords = []
            
            # 1. Playwrightë¡œ ì‹¤ì œ Google Trends í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
            try:
                self._log("Playwright import ì‹œë„ ì¤‘...")
                from playwright.sync_api import sync_playwright
                
                self._log("Playwrightë¡œ Google Trends í˜ì´ì§€ ì ‘ê·¼ ì¤‘...")
                
                with sync_playwright() as p:
                    browser = p.chromium.launch(headless=True)
                    page = browser.new_page()
                    
                    # Google Trends í˜ì´ì§€ ì ‘ì†
                    page.goto('https://trends.google.co.kr/trending?geo=KR&hours=24', timeout=30000)
                    
                    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                    page.wait_for_selector('tr[role="row"]', timeout=10000)
                    
                    # JavaScriptë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
                    keywords = page.evaluate('''() => {
                        const rows = document.querySelectorAll('tr[role="row"]');
                        const keywords = [];
                        rows.forEach(row => {
                            const cells = row.querySelectorAll('td');
                            if (cells.length >= 2) {
                                const keywordDiv = cells[1].querySelector('div');
                                if (keywordDiv) {
                                    keywords.push(keywordDiv.innerText.trim());
                                }
                            }
                        });
                        return keywords;
                    }''')
                    
                    browser.close()
                    
                    if keywords:
                        self._log(f"Playwrightë¡œ {len(keywords)}ê°œ í‚¤ì›Œë“œ íšë“")
                        return keywords
                        
            except Exception as playwright_error:
                import traceback
                self._log(f"Playwright íŠ¸ë Œë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {playwright_error}")
                self._log(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")

            # 2. RSS í”¼ë“œ ì‹œë„ (Fallback)
            try:
                import requests
                import xml.etree.ElementTree as ET
                
                rss_url = "https://trends.google.com/trends/trendingsearches/daily/rss?geo=KR"
                response = requests.get(rss_url, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                })
                
                if response.status_code == 200:
                    root = ET.fromstring(response.content)
                    for item in root.findall('.//item'):
                        title = item.find('title')
                        if title is not None:
                            keywords.append(title.text)
                    self._log(f"RSS í”¼ë“œì—ì„œ {len(keywords)}ê°œ í‚¤ì›Œë“œ íšë“")
                else:
                    self._log(f"RSS ìš”ì²­ ì‹¤íŒ¨: Status Code {response.status_code}")
            except Exception as rss_error:
                self._log(f"RSS íŠ¸ë Œë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {rss_error}")

            if keywords:
                return keywords

            # 3. Pytrends ì‹œë„ (Fallback)
            try:
                trending_searches = self.pytrends.trending_searches(pn='south_korea')
                keywords = trending_searches[0].tolist()
                self._log(f"Pytrendsì—ì„œ {len(keywords)}ê°œ í‚¤ì›Œë“œ íšë“")
            except Exception as py_error:
                self._log(f"Pytrends ì‹¤íŒ¨: {py_error}")

            if keywords:
                return keywords
            
            # 4. ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ë°˜í™˜
            self._log("ëª¨ë“  íŠ¸ë Œë“œ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return ['ìƒì„±í˜• AI', 'íŒŒì´ì¬ ìë™í™”', 'ì£¼ë§ ë‚ ì”¨', 'ìµœì‹  ì˜í™” ìˆœìœ„', 'ë§›ì§‘ ì¶”ì²œ']
        
        except Exception as e:
            self._log(f"íŠ¸ë Œë“œ ê°€ì ¸ì˜¤ê¸° ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            return ['í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ']
    
    def fetch_google_news(self, keyword, max_news=3):
        """
        Google ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            list: [{'title': str, 'url': str, 'image': str, 'summary': str, 'source': str}, ...]
        """
        try:
            self._log(f"'{keyword}' ê´€ë ¨ Google ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
            
            from playwright.sync_api import sync_playwright
            import urllib.parse
            
            news_list = []
            
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                
                # Google ë‰´ìŠ¤ ê²€ìƒ‰
                search_url = f"https://www.google.com/search?q={urllib.parse.quote(keyword)}&tbm=nws&hl=ko"
                page.goto(search_url, timeout=30000)
                page.wait_for_timeout(2000)
                
                # ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
                news_data = page.evaluate('''() => {
                    const newsItems = [];
                    const articles = document.querySelectorAll('div.SoaBEf, div.WlydOe');
                    
                    for (let i = 0; i < Math.min(articles.length, 3); i++) {
                        const article = articles[i];
                        
                        // ì œëª©
                        const titleElem = article.querySelector('div[role="heading"]');
                        const title = titleElem ? titleElem.innerText : '';
                        
                        // URL
                        const linkElem = article.querySelector('a');
                        const url = linkElem ? linkElem.href : '';
                        
                        // ì´ë¯¸ì§€
                        const imgElem = article.querySelector('img');
                        const image = imgElem ? imgElem.src : '';
                        
                        // ìš”ì•½
                        const summaryElem = article.querySelector('div.GI74Re');
                        const summary = summaryElem ? summaryElem.innerText : '';
                        
                        // ì¶œì²˜ - ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„
                        let source = '';
                        
                        // ë°©ë²• 1: CEMjEf í´ë˜ìŠ¤
                        let sourceElem = article.querySelector('div.CEMjEf span');
                        if (sourceElem) {
                            source = sourceElem.innerText;
                        }
                        
                        // ë°©ë²• 2: MgUUmf í´ë˜ìŠ¤ (ë‰´ìŠ¤ ì¶œì²˜)
                        if (!source) {
                            sourceElem = article.querySelector('.MgUUmf.NUnG9d span');
                            if (sourceElem) source = sourceElem.innerText;
                        }
                        
                        // ë°©ë²• 3: URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
                        if (!source && url) {
                            try {
                                const urlObj = new URL(url);
                                source = urlObj.hostname.replace('www.', '');
                            } catch (e) {
                                source = '';
                            }
                        }
                        
                        if (title && url) {
                            newsItems.push({
                                title: title,
                                url: url,
                                image: image,
                                summary: summary || title,
                                source: source || 'Unknown Source'
                            });
                        }
                    }
                    
                    return newsItems;
                }''')
                
                browser.close()
                
                if news_data:
                    self._log(f"{len(news_data)}ê°œì˜ ë‰´ìŠ¤ í•­ëª© ë°œê²¬")
                    return news_data[:max_news]
                
        except Exception as e:
            self._log(f"Google ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
        return []
    
    def fetch_ai_image(self, keyword):
        """
        Gemini Imagen 3ë¥¼ ì‚¬ìš©í•˜ì—¬ AI ì´ë¯¸ì§€ ìƒì„±
        """
        try:
            self._log(f"'{keyword}' ê´€ë ¨ AI ì´ë¯¸ì§€ ìƒì„± ì‹œë„ ì¤‘...")
            import os
            import requests
            from datetime import datetime
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                self._log("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ì´ë¯¸ì§€ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return None
                
            # Imagen 4.0 API í˜¸ì¶œ (REST)
            url = f"https://generativelanguage.googleapis.com/v1beta/models/imagen-4.0-generate-001:predict?key={api_key}"
            
            # ë³´ë‹¤ êµ¬ì²´ì ì¸ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ê°€ê³µ
            prompt = f"A professional, photorealistic blog header image for the topic: '{keyword}'. High quality, centered composition, no text."
            
            data = {
                "instances": [{"prompt": prompt}],
                "parameters": {"sampleCount": 1}
            }
            
            response = requests.post(url, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if "predictions" in result and len(result["predictions"]) > 0:
                    # ì‘ë‹µì€ ë³´í†µ base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
                    b64_data = result["predictions"][0].get("bytesBase64Encoded")
                    if b64_data:
                        import base64
                        image_data = base64.b64decode(b64_data)
                        
                        # ë¡œì»¬ ì €ì¥
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        filename = f"ai_featured_{timestamp}.png"
                        filepath = os.path.join(self.blog_posts_dir, 'images', filename)
                        
                        if not os.path.exists(os.path.join(self.blog_posts_dir, 'images')):
                            os.makedirs(os.path.join(self.blog_posts_dir, 'images'))
                            
                        with open(filepath, 'wb') as f:
                            f.write(image_data)
                            
                        self._log(f"AI ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {filepath}")
                        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì°¸ì¡° ê°€ëŠ¥í•˜ë„ë¡ ìƒëŒ€ ê²½ë¡œ ë°˜í™˜
                        return f"images/{filename}"
            
            # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ë‚¨ê¸°ê³  None ë°˜í™˜ (ìë™ìœ¼ë¡œ ê¸°ì¡´ êµ¬ê¸€ ì´ë¯¸ì§€ fetchë¡œ ë„˜ì–´ê°)
            self._log(f"AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (HTTP {response.status_code}): {response.text[:100]}")
            return None
        except Exception as e:
            self._log(f"AI ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def fetch_google_image(self, keyword):
        """
        Google ì´ë¯¸ì§€ ê²€ìƒ‰ì—ì„œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            str: ì´ë¯¸ì§€ URL ë˜ëŠ” None
        """
        try:
            self._log(f"'{keyword}' ê´€ë ¨ Google ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
            
            from playwright.sync_api import sync_playwright
            import urllib.parse
            
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                
                # Google ì´ë¯¸ì§€ ê²€ìƒ‰
                search_url = f"https://www.google.com/search?q={urllib.parse.quote(keyword)}&tbm=isch&hl=ko"
                page.goto(search_url, timeout=30000)
                page.wait_for_timeout(2000)
                
                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_url = page.evaluate('''() => {
                    const img = document.querySelector('img[data-src], img.rg_i');
                    if (img) {
                        return img.src || img.getAttribute('data-src');
                    }
                    return null;
                }''')
                
                browser.close()
                
                if image_url and image_url.startswith('http'):
                    self._log(f"ëŒ€í‘œ ì´ë¯¸ì§€ ë°œê²¬: {image_url[:50]}...")
                    return image_url
                
        except Exception as e:
            self._log(f"Google ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
    def fetch_youtube_video(self, keyword):
        """
        YouTubeì—ì„œ ê´€ë ¨ ì¸ê¸° ì˜ìƒì˜ ì„ë² ë”© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        """
        try:
            self._log(f"'{keyword}' ê´€ë ¨ YouTube ì˜ìƒ ê²€ìƒ‰ ì¤‘...")
            import requests
            import re
            search_query = f"{keyword} ìµœì‹  ë‰´ìŠ¤"
            url = f"https://www.youtube.com/results?search_query={search_query}"
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                # ë¹„ë””ì˜¤ ëª©ë¡ì—ì„œ ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ë¹„ë””ì˜¤ IDë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•´ "videoRenderer" íŒ¨í„´ ì‚¬ìš©
                # ì´ëŠ” ìœ íŠœë¸Œ ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ì˜ JSON ë°ì´í„° êµ¬ì¡°ì—ì„œ ë¹„ë””ì˜¤ í•­ëª©ì„ ì‹ë³„í•˜ëŠ” í‚¤ì›Œë“œì…ë‹ˆë‹¤.
                results = re.findall(r"\"videoRenderer\":\{\"videoId\":\"([^\"]+)\"", response.text)
                if results:
                    # ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©
                    video_id = results[0]
                    self._log(f"ìœ íŠœë¸Œ ì˜ìƒ ë°œê²¬: https://youtu.be/{video_id}")
                    return f'<iframe width="100%" height="450" src="https://www.youtube.com/embed/{video_id}" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>'
                
                # ì°¨ì„ ì±…: ê¸°ì¡´ì˜ ë‹¨ìˆœ videoId ì¶”ì¶œ (ìµœì‹  ë°ì´í„° êµ¬ì¡° ëŒ€ì‘)
                video_ids = re.findall(r"\"videoId\":\"([^\"]+)\"", response.text)
                if video_ids:
                    video_id = video_ids[0]
                    self._log(f"ìœ íŠœë¸Œ ì˜ìƒ ë°œê²¬(ì°¨ì„ ì±…): https://youtu.be/{video_id}")
                    return f'<iframe width="100%" height="450" src="https://www.youtube.com/embed/{video_id}" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>'
            return None
        except Exception as e:
            self._log(f"YouTube ì˜ìƒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    def get_related_posts(self, current_keyword):
        """
        ê¸°ì¡´ ê²Œì‹œë¬¼ ì¤‘ í˜„ì¬ í‚¤ì›Œë“œì™€ ì—°ê´€ì„± ë†’ì€ 2ê°œ ì„ ì •
        """
        try:
            if not os.path.exists(self.blog_posts_dir):
                return []
                
            all_files = [f for f in os.listdir(self.blog_posts_dir) if f.endswith('.md')]
            if not all_files:
                return []
            
            # í˜„ì¬ í‚¤ì›Œë“œ ì œì™¸
            other_files = [f for f in all_files if current_keyword not in f]
            if not other_files:
                return []
            
            # ê°„ë‹¨í•˜ê²Œ ìµœê·¼ ê²Œì‹œë¬¼ 2ê°œ ë°˜í™˜
            other_files.sort(reverse=True)
            related = []
            for f in other_files[:2]:
                # íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (timestamp_keyword.md)
                parts = f.replace('.md', '').split('_')
                if len(parts) >= 3:
                    title = " ".join(parts[2:]) # ì–¸ë”ìŠ¤ì½”ì–´ê°€ ë” ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
                    related.append({'title': title, 'filename': f})
                else:
                    # í˜•ì‹ì´ ë‹¤ë¥´ë©´ ê·¸ëƒ¥ íŒŒì¼ëª… ì‚¬ìš©
                    related.append({'title': f.replace('.md', ''), 'filename': f})
            return related
        except Exception as e:
            self._log(f"ê´€ë ¨ ê²Œì‹œë¬¼ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
            
    
    def select_keyword(self, keywords):
        """
        ì‚¬ìš©ë˜ì§€ ì•Šì€ ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ì„ íƒ
        
        Args:
            keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            str: ì„ íƒëœ í‚¤ì›Œë“œ ë˜ëŠ” None
        """
        used_keywords = self._load_used_keywords()
        
        for keyword in keywords:
            if keyword not in used_keywords:
                self._log(f"ì„ íƒëœ í‚¤ì›Œë“œ: {keyword}")
                return keyword
        
        self._log("ì‚¬ìš© ê°€ëŠ¥í•œ ìƒˆë¡œìš´ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    def _analyze_keyword_category(self, keyword):
        """
        í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„ì„ (Gemini ì‚¬ìš©) - ì„¸ë¶„í™”ëœ 14ê°œ ì¹´í…Œê³ ë¦¬
        """
        try:
            prompt = f"""
            ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³ , ê¸€ì˜ í•µì‹¬ í¬ì»¤ìŠ¤ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
            
            [í‚¤ì›Œë“œ] : {keyword}
            
            [ì„¸ë¶€ ì¹´í…Œê³ ë¦¬]
            1. SPORTS_MATCH (ê²½ê¸° ì¼ì •, ê²°ê³¼, ì¤‘ê³„ ì •ë³´)
            2. SPORTS_GENERAL (ì„ ìˆ˜ ì´ì , ë¶€ìƒ, íŒ€ ì´ìŠˆ, ì¼ë°˜ ìŠ¤í¬ì¸  ë‰´ìŠ¤)
            3. STOCK (ê°œë³„ ì£¼ì‹ ì¢…ëª©, ê¸°ì—… ì‹¤ì , ê³µì‹œ)
            4. ECONOMY (ê±°ì‹œ ê²½ì œ, ë¶€ë™ì‚°, ì •ì±…, í™˜ìœ¨, ê¸ˆë¦¬)
            5. SOCIAL_ISSUE (ì‚¬íšŒì  ë…¼ë€, ìŸì , ì°¬ë°˜ í† ë¡ )
            6. SOCIAL_INCIDENT (ì‚¬ê±´, ì‚¬ê³ , ì¬í•´, íŒ©íŠ¸ ì¤‘ì‹¬)
            7. POLITICS (ì •ì¹˜, ì„ ê±°, ì •ë‹¹, ë²•ì•ˆ)
            8. ENTERTAINMENT_NEWS (ì—°ì˜ˆì¸ ê°€ì‹­, ì—´ì• , ì‚¬ê±´, ê·¼í™©)
            9. ENTERTAINMENT_CONTENT (ë“œë¼ë§ˆ, ì˜í™”, ì›¹íˆ°, ë°©ì†¡ í”„ë¡œê·¸ë¨ ë¦¬ë·°/ì •ë³´)
            10. TECH_DEVICE (ìŠ¤ë§ˆíŠ¸í°, ê°€ì „, í•˜ë“œì›¨ì–´ ìŠ¤í™/ë¹„êµ)
            11. TECH_TREND (IT ì„œë¹„ìŠ¤, AI, í”Œë«í¼, ì†Œí”„íŠ¸ì›¨ì–´ íŠ¸ë Œë“œ)
            12. HEALTH (ê±´ê°• ì •ë³´, ì§ˆë³‘, ìš´ë™, ì˜í•™)
            13. LIVING_INFO (ìƒí™œ ê¿€íŒ, ë‚ ì”¨, ì—¬í–‰, ìš”ë¦¬, ì‡¼í•‘ ì •ë³´)
            14. OTHER (ê·¸ ì™¸ ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš´ ì¼ë°˜ ì •ë³´)
            
            [ì‘ë‹µ í˜•ì‹]
            Category: [ì¹´í…Œê³ ë¦¬ëª…]
            Focus: [í•µì‹¬ í¬ì»¤ìŠ¤]
            """
            
            response = self.model.generate_content(prompt)
            result = response.text.strip()
            
            category = "OTHER"
            focus = "ì •ë³´ ì „ë‹¬ ë° ê°œìš” ì„¤ëª…"
            
            for line in result.split('\n'):
                if line.startswith('Category:'):
                    category = line.replace('Category:', '').strip().upper()
                elif line.startswith('Focus:'):
                    focus = line.replace('Focus:', '').strip()
            
            # ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ì¸ì§€ í™•ì¸
            valid_categories = [
                'SPORTS_MATCH', 'SPORTS_GENERAL', 
                'STOCK', 'ECONOMY', 
                'SOCIAL_ISSUE', 'SOCIAL_INCIDENT', 'POLITICS',
                'ENTERTAINMENT_NEWS', 'ENTERTAINMENT_CONTENT',
                'TECH_DEVICE', 'TECH_TREND',
                'HEALTH', 'LIVING_INFO', 'OTHER'
            ]
            
            # ë§¤ì¹­ë˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ ìœ ì‚¬í•œ ê²ƒ ì°¾ê±°ë‚˜ OTHER
            if category not in valid_categories:
                # ê³µë°±ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµ ë“± ìœ ì—°í•œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë‚˜ ì¼ë‹¨ OTHER
                category = 'OTHER'
                
            self._log(f"í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼: {category} / {focus}")
            return category, focus
            
        except Exception as e:
            self._log(f"í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "OTHER", "ì •ë³´ ì „ë‹¬"

    def _get_persona_instruction(self):
        """
        ì„¤ì •ëœ í˜ë¥´ì†Œë‚˜ì— ë”°ë¥¸ ê¸€ì“°ê¸° ì§€ì¹¨ ë°˜í™˜
        """
        if self.persona == 'professional':
            return """
            [Persona: Professional (ì „ë¬¸ê°€í˜•)]
            - ë§íˆ¬: ì‹ ë¢°ê° ìˆê³  ê¹”ë”í•œ 'í•˜ì‹­ì‹œì˜¤ì²´' ë˜ëŠ” ë‹¨ì •í•œ 'í•´ìš”ì²´'ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
            - ì–´ì¡°: ê°ê´€ì ì´ê³  ê¶Œìœ„ ìˆëŠ” ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ì „ë¬¸ê°€ì˜ ëª©ì†Œë¦¬ë¥¼ ìœ ì§€í•˜ì‹­ì‹œì˜¤.
            - íŠ¹ì§•: ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ë¥¼ ì¤„ì´ê³ , ì •í™•í•œ ìš©ì–´ì™€ ë…¼ë¦¬ì ì¸ êµ¬ì¡°ë¡œ ë…ìì˜ ì´í•´ë¥¼ ë•ìŠµë‹ˆë‹¤.
            """
        elif self.persona == 'analytical':
            return """
            [Persona: Analytical (ë¶„ì„ê°€í˜•)]
            - ë§íˆ¬: ë…¼ë¦¬ì ì´ê³  ê°ê´€ì ì¸ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. (~ì…ë‹ˆë‹¤, ~í•¨)
            - ì–´ì¡°: í˜„ìƒì˜ ì´ë©´ì„ ë¶„ì„í•˜ê³  ë°ì´í„°ë‚˜ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ê°ë„ì˜ ì‹œê°ì„ ì œê³µí•˜ì‹­ì‹œì˜¤.
            - íŠ¹ì§•: ë‹¨ìˆœ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´ 'ì™œ' ì´ëŸ° ì¼ì´ ì¼ì–´ë‚¬ëŠ”ì§€, ì•ìœ¼ë¡œ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
            """
        else:  # friendly (default)
            return """
            [Persona: Friendly (ì¹œê·¼í•œ ì´ì›ƒí˜•)]
            - ë§íˆ¬: ë‹¤ì •í•˜ê³  ì¹œê·¼í•œ 'í•´ìš”ì²´'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ê°€ë” ì´ëª¨ì§€(ğŸ˜Š, âœ¨ ë“±)ë¥¼ ì ì ˆíˆ ì„ì–´ì£¼ì„¸ìš”.
            - ì–´ì¡°: ì¹œêµ¬ì—ê²Œ ì´ì•¼ê¸°í•˜ë“¯ í¸ì•ˆí•˜ë©´ì„œë„ ìœ ìµí•œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ë”°ëœ»í•œ ëª©ì†Œë¦¬ì…ë‹ˆë‹¤.
            - íŠ¹ì§•: ë…ìì˜ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” ë¬¸êµ¬(ì˜ˆ: "ì—¬ëŸ¬ë¶„ë„ ê¶ê¸ˆí•˜ì…¨ì£ ?", "ì •ë§ ë†€ëì§€ ì•Šë‚˜ìš”?")ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
            """

    def _get_category_prompt(self, keyword, category, news_items_text, news_summary):
        """
        ì„¸ë¶„í™”ëœ ì¹´í…Œê³ ë¦¬ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ ìƒì„± (í˜ë¥´ì†Œë‚˜ ë° íŒ©íŠ¸ì²´í¬ í¬í•¨)
        """
        persona_instruction = self._get_persona_instruction()
        
        fact_check_instruction = """
        [Fact-Check ë° ì •ë³´ í†µí•© ì§€ì¹¨]
        - ì œê³µëœ ì—¬ëŸ¬ ë‰´ìŠ¤ í•­ëª©({len(news_items_text)}ê°œ)ì„ ë©´ë°€íˆ ë¹„êµí•˜ì—¬ ê³µí†µëœ í•µì‹¬ ì‚¬ì‹¤ì„ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤.
        - ë‰´ìŠ¤ ê°„ì— ë‚´ìš©ì´ ìƒì¶©ë˜ëŠ” ê²½ìš°, ê°€ì¥ ìµœì‹ ì˜ ì •ë³´ì´ê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ë³´ë„ë¥¼ ìš°ì„ ì‹œí•˜ë˜, ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ '~ë¼ê³  ì „í•´ì¡ŒìŠµë‹ˆë‹¤'ì™€ ê°™ì€ ì‹ ì¤‘í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
        - ë‹¨ìˆœíˆ ê¸°ì‚¬ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì „ì²´ì ì¸ ë§¥ë½ì„ íŒŒì•…í•˜ì—¬ í•˜ë‚˜ì˜ ì™„ì„±ëœ ìŠ¤í† ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì‹­ì‹œì˜¤.
        """

        base_instructions = f"""
        ì´ ê¸€ì€ ë°˜ë“œì‹œ 'front-matter + ë³¸ë¬¸'ì„ í•¨ê»˜ ìƒì„±í•´ì•¼ í•˜ë©°,
        front-matterì˜ ì„±ê²©ì€ ë³¸ë¬¸ ë‚´ìš©ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•œë‹¤.
        
        {persona_instruction}
        
        {fact_check_instruction}
        
        [Front-matter ì‘ì„± ê·œì¹™]
        - title: '{keyword}' + (ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„±ì— ë§ëŠ” ë§¤ë ¥ì ì¸ ì œëª©)
        - categories: ë°˜ë“œì‹œ [ì •ë³´, ë¶„ì„, í›„ê¸°] ë“± ì ì ˆí•œ ê²ƒ ì„ íƒ (íŠ¸ë Œë“œ ì‚¬ìš© ê¸ˆì§€)
        - tags: ['{keyword}', ê´€ë ¨íƒœê·¸1, ê´€ë ¨íƒœê·¸2]
        - description: ê¸€ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•œ ë©”íƒ€ ì„¤ëª…
        
        [ê³µí†µ ì‘ì„± ì›ì¹™]
        - ê°€ë…ì„±ì„ ìœ„í•´ ì ì ˆí•œ ì†Œí—¤ë”ì™€ ë¶ˆë › í¬ì¸íŠ¸ ì‚¬ìš©
        - 'ìµœì‹ ', 'íŠ¸ë Œë“œ' ê°™ì€ ë‹¨ì–´ ë‚¨ë°œ ê¸ˆì§€
        - Markdown í˜•ì‹ ì¤€ìˆ˜
        """

        # 1. ìŠ¤í¬ì¸  ë§¤ì¹˜ (ê²½ê¸° ì¤‘ì‹¬)
        if category == 'SPORTS_MATCH':
            return f"""
            '{keyword}'ì— ëŒ€í•œ ìŠ¤í¬ì¸  ê²½ê¸° í”„ë¦¬ë·° ë˜ëŠ” ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì¤˜.
            
            [ìƒí™© íŒë‹¨ (í˜„ì¬: {datetime.now().strftime('%Y-%m-%d')})]
            ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ê¸°ê°€ 'ì˜ˆì •'ì¸ì§€ 'ì¢…ë£Œ'ì¸ì§€ íŒŒì•…í•˜ì—¬ ì‘ì„±.
            
            A. ì˜ˆì •ëœ ê²½ê¸°:
               - ì¼ì •(í•œêµ­ ì‹œê°„), ì¥ì†Œ
               - **ì¤‘ê³„ ì±„ë„ ë° ì‹œì²­ ë°©ë²•** (ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë‹¤ë£¸)
               - ì–‘íŒ€ ì „ë ¥/ìƒëŒ€ ì „ì /ê´€ì „ í¬ì¸íŠ¸
               
            B. ì¢…ë£Œëœ ê²½ê¸°:
               - **ìŠ¤ì½”ì–´ ë° ê²½ê¸° ê²°ê³¼**
               - ì£¼ìš” í•˜ì´ë¼ì´íŠ¸ ì¥ë©´ ì„¤ëª…
               - ìŠ¹íŒ¨ ìš”ì¸ ë¶„ì„ ë° ì„ ìˆ˜ í™œì•½ìƒ
               - ë‹¤ìŒ ì¼ì •
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """
            
        # 2. ìŠ¤í¬ì¸  ì¼ë°˜ (ì„ ìˆ˜, íŒ€)
        elif category == 'SPORTS_GENERAL':
            return f"""
            '{keyword}'ì— ëŒ€í•œ ìŠ¤í¬ì¸  ì´ìŠˆ/ì„ ìˆ˜ ì •ë³´ë¥¼ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì´ìŠˆì˜ í•µì‹¬ ë‚´ìš© (ì´ì , ë¶€ìƒ, ê¸°ë¡ ë‹¬ì„± ë“±)
            - í•´ë‹¹ ì„ ìˆ˜ì˜ ìµœê·¼ í™œì•½ìƒ ë˜ëŠ” íŒ€ ë¶„ìœ„ê¸°
            - íŒ¬ë“¤ì˜ ë°˜ì‘ ë° ì „ë¬¸ê°€ ì˜ê²¬
            - í–¥í›„ ì˜ˆìƒë˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """
            
        # 3. ì£¼ì‹ (ê°œë³„ ì¢…ëª©)
        elif category == 'STOCK':
            return f"""
            '{keyword}' ì£¼ê°€ íë¦„ ë° ê¸°ì—… ì´ìŠˆ ë¶„ì„ ê¸€ì„ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - í˜„ì¬ ì£¼ê°€ ë™í–¥ ë° ìµœê·¼ íë¦„
            - **ìƒìŠ¹/í•˜ë½ì˜ êµ¬ì²´ì  ì›ì¸** (í˜¸ì¬/ì•…ì¬, ì‹¤ì , ê³µì‹œ)
            - ì¦ê¶Œê°€ ëª©í‘œê°€ ë¦¬í¬íŠ¸ ë° íˆ¬ì ì˜ê²¬ ìš”ì•½
            - í–¥í›„ ì£¼ê°€ ì „ë§ ë° ì²´í¬í¬ì¸íŠ¸
            
            * ì£¼ì˜: "ë¬´ì¡°ê±´ ì‚¬ë¼/íŒ”ë¼"ëŠ” ì‹ì˜ ì¡°ì–¸ ê¸ˆì§€. ê°ê´€ì  ì •ë³´ ìœ„ì£¼.
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """
            
        # 4. ê²½ì œ (ê±°ì‹œ/ë¶€ë™ì‚°/ì •ì±…)
        elif category == 'ECONOMY':
            return f"""
            '{keyword}' ê´€ë ¨ ê²½ì œ/ì •ì±… ì´ìŠˆ í•´ì„¤ ê¸€ì„ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì´ìŠˆ ê°œìš” ë° ë°°ê²½ ì„¤ëª… (ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ)
            - ì´ê²ƒì´ ìš°ë¦¬ ì‚¶/ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥
            - ì°¬ë°˜ ì˜ê²¬ì´ë‚˜ ë‹¤ì–‘í•œ ì‹œê°
            - ìš”ì•½ ë° ì‹œì‚¬ì 
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """
            
        # 5. ì‚¬íšŒ ì´ìŠˆ (ë…¼ë€/ìŸì )
        elif category == 'SOCIAL_ISSUE':
            return f"""
            '{keyword}' ê´€ë ¨ ì‚¬íšŒì  ì´ìŠˆ/ë…¼ë€ ì •ë¦¬ ê¸€ì„ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ë…¼ë€ì˜ ë°œë‹¨ ë° í•µì‹¬ ìŸì 
            - ê°ê³„ì˜ ì…ì¥ (ì°¬ì„± vs ë°˜ëŒ€, í˜¹ì€ Aì¸¡ vs Bì¸¡)
            - ëŒ€ì¤‘ì˜ ë°˜ì‘ (ì»¤ë®¤ë‹ˆí‹°, ëŒ“ê¸€ ë¶„ìœ„ê¸° ë“±)
            - ì‹œì‚¬í•˜ëŠ” ë°” ë° í–¥í›„ ì „ê°œ ì˜ˆìƒ
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 6. ì‚¬íšŒ ì‚¬ê±´ (íŒ©íŠ¸ ì¤‘ì‹¬)
        elif category == 'SOCIAL_INCIDENT':
            return f"""
            '{keyword}' ì‚¬ê±´/ì‚¬ê³  ì¢…í•© ì •ë¦¬ ê¸€ì„ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì‚¬ê±´ ë°œìƒ ì¼ì‹œ, ì¥ì†Œ, ê²½ìœ„ (ìœ¡í•˜ì›ì¹™)
            - í˜„ì¬ê¹Œì§€ì˜ ìˆ˜ì‚¬/ì§„í–‰ ìƒí™©
            - í”¼í•´ ê·œëª¨ ë˜ëŠ” ì‚¬íšŒì  íŒŒì¥
            - ê´€ë ¨ ì£¼ì˜ì‚¬í•­ (ìœ ì‚¬ í”¼í•´ ë°©ì§€ ë“±)
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 7. ì •ì¹˜
        elif category == 'POLITICS':
            return f"""
            '{keyword}' ê´€ë ¨ ì •ì¹˜ ì´ìŠˆ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì´ìŠˆì˜ í•µì‹¬ ë‚´ìš© ë° íŒ©íŠ¸
            - ì—¬/ì•¼ í˜¹ì€ ê´€ë ¨ ì •ì¹˜ì¸ë“¤ì˜ ë°œì–¸ ë° ì…ì¥ ì°¨ì´
            - ì´ë²ˆ ì‚¬ì•ˆì´ ê°–ëŠ” ì •ì¹˜ì  ì˜ë¯¸
            - í–¥í›„ ì¼ì • ë° ì˜ˆìƒ ì‹œë‚˜ë¦¬ì˜¤
            
            * ìµœëŒ€í•œ ì¤‘ë¦½ì ì´ê³  ê°ê´€ì ì¸ í†¤ ìœ ì§€.
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 8. ì—°ì˜ˆ ë‰´ìŠ¤ (ê°€ì‹­/ê·¼í™©)
        elif category == 'ENTERTAINMENT_NEWS':
            return f"""
            '{keyword}' ê´€ë ¨ ì—°ì˜ˆê³„ ì†Œì‹ì„ ì •ë¦¬í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ ìƒì„¸ ë‚´ìš© (ê¸°ì‚¬ ë‚´ìš© ê¸°ë°˜)
            - ì†Œì†ì‚¬ ê³µì‹ ì…ì¥ í˜¹ì€ ë³¸ì¸ í•´ëª…
            - ë„¤í‹°ì¦Œ/íŒ¬ë“¤ì˜ ë°˜ì‘
            - ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ í˜¹ì€ ë°°ê²½ ì§€ì‹
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 9. ì—°ì˜ˆ ì½˜í…ì¸  (ë“œë¼ë§ˆ/ì˜í™” ë¦¬ë·°)
        elif category == 'ENTERTAINMENT_CONTENT':
            return f"""
            '{keyword}' (ë“œë¼ë§ˆ/ì˜í™”/ë°©ì†¡) í”„ë¦¬ë·° ë˜ëŠ” ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ê¸°ë³¸ ì •ë³´ (ì¶œì—°ì§„, ì¤„ê±°ë¦¬, ë°©ì˜ì‹œê°„/ê°œë´‰ì¼)
            - ê´€ì „ í¬ì¸íŠ¸ í˜¹ì€ ê°ìƒ í¬ì¸íŠ¸ (ì¬ë¯¸ ìš”ì†Œ)
            - ì‹œì²­ë¥ /ê´€ê°ìˆ˜ ì¶”ì´ ë° ë°˜ì‘
            - (ì¢…ì˜/ê²°ë§ì¸ ê²½ìš°) ê²°ë§ ìš”ì•½ ë° í•´ì„
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 10. í…Œí¬ ê¸°ê¸° (í•˜ë“œì›¨ì–´)
        elif category == 'TECH_DEVICE':
            return f"""
            '{keyword}' ì œí’ˆì— ëŒ€í•œ ìŠ¤í™/ì •ë³´ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì£¼ìš” ìŠ¤í™ ë° ë””ìì¸ íŠ¹ì§•
            - ì „ì‘ ëŒ€ë¹„ ë‹¬ë¼ì§„ ì  (Upgrades)
            - ì¥ì  ë° ë‹¨ì  (ë¹„íŒì  ì‹œê° í¬í•¨)
            - ì¶œì‹œì¼, ê°€ê²©, êµ¬ë§¤ ì •ë³´
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 11. í…Œí¬ íŠ¸ë Œë“œ (IT/AI)
        elif category == 'TECH_TREND':
            return f"""
            '{keyword}' ê´€ë ¨ IT/í…Œí¬ íŠ¸ë Œë“œ ë¶„ì„ ê¸€ì„ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ê¸°ìˆ /ì„œë¹„ìŠ¤ì˜ ê°œë… ì •ì˜
            - ìµœê·¼ í™”ì œê°€ ëœ ì´ìœ  (ìƒˆë¡œìš´ ê¸°ëŠ¥, ì—…ë°ì´íŠ¸ ë“±)
            - ì—…ê³„ ë™í–¥ ë° ê²½ìŸì‚¬ ìƒí™©
            - í–¥í›„ ì „ë§ ë° ì‚¬ìš©ìì—ê²Œ ë¯¸ì¹˜ëŠ” ì˜í–¥
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 12. ê±´ê°•
        elif category == 'HEALTH':
            return f"""
            '{keyword}' ê´€ë ¨ ê±´ê°•/ì˜í•™ ì •ë³´ë¥¼ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì¦ìƒ ë° ì›ì¸ ì„¤ëª…
            - ì¹˜ë£Œ ë°©ë²• ë° ì˜ˆë°© ìˆ˜ì¹™
            - ì¢‹ì€ ìŒì‹/ë‚˜ìœ ìŒì‹ í˜¹ì€ ìƒí™œ ìŠµê´€
            - ì „ë¬¸ê°€ ì¡°ì–¸ (ë‰´ìŠ¤ ê¸°ë°˜)
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """

        # 13. ìƒí™œ ì •ë³´ (ë¦¬ë¹™)
        elif category == 'LIVING_INFO':
            return f"""
            '{keyword}' ê´€ë ¨ ìƒí™œ ê¿€íŒ/ì •ë³´ë¥¼ ì‘ì„±í•´ì¤˜.
            
            [í•„ìˆ˜ í¬í•¨ ë‚´ìš©]
            - ì´ê²Œ ì™œ í•„ìš”í•œì§€/ë¬´ì—‡ì¸ì§€ (ê´€ì‹¬ ìœ ë°œ)
            - êµ¬ì²´ì ì¸ ì •ë³´ (ë‚ ì”¨ë¼ë©´ ì˜ˆë³´, ì¶•ì œë¼ë©´ ì¼ì •/ì¥ì†Œ, ìš”ë¦¬ë¼ë©´ ë ˆì‹œí”¼)
            - ì´ìš© ê¿€íŒ ë° ì£¼ì˜ì‚¬í•­
            - ìš”ì•½
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """
            
        # 14. ê¸°íƒ€ (OTHER)
        else:
            return f"""
            '{keyword}'ì— ëŒ€í•´ ì •ë³´ë¥¼ ì°¾ëŠ” ì‚¬ìš©ìë¥¼ ìœ„í•œ ì¹œì ˆí•œ ì„¤ëª… ê¸€ì„ ì‘ì„±í•´ì¤˜.
            
            [ì‘ì„± í¬ì¸íŠ¸]
            - '{keyword}'ì˜ ì •ì˜ ë° í•µì‹¬ ê°œìš”
            - ìµœê·¼ ì´ìŠˆê°€ ëœ ì´ìœ  (ìˆë‹¤ë©´)
            - ì‚¬ëŒë“¤ì´ ê¶ê¸ˆí•´í•  ë§Œí•œ 3ê°€ì§€ í¬ì¸íŠ¸
            - ê²°ë¡  ë° ìš”ì•½
            
            [ì°¸ê³  ë‰´ìŠ¤]
            {news_summary}
            
            {base_instructions}
            """
    
    def generate_blog_content(self, keyword):
        """
        ì„ íƒëœ í‚¤ì›Œë“œë¡œ ì¹´í…Œê³ ë¦¬ë³„ ë§ì¶¤ ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„±
        """
        if not self.client_ready:
            return f"<h1>{keyword}ì— ëŒ€í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸</h1><p>(API í‚¤ ì„¤ì • í•„ìš”)</p>"
        
        try:
            self._log(f"'{keyword}' í‚¤ì›Œë“œë¡œ ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„± ì‹œì‘...")
            
            # 1. Google ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            news_items = self.fetch_google_news(keyword, max_news=5)
            
            # ë‰´ìŠ¤ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ ì°¸ê³ ìš©)
            news_summary = ""
            if news_items:
                for idx, item in enumerate(news_items):
                    news_summary += f"{idx+1}. {item['title']} ({item.get('source', '')}): {item['summary']}\n"
            else:
                news_summary = "ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì •ë³´ì— ê¸°ë°˜í•´ ì‘ì„±í•´ì£¼ì„¸ìš”."

            # 2. í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„ì„
            category, category_focus = self._analyze_keyword_category(keyword)
            
            # 3. ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° (AI ìš°ì„ , ì‹¤íŒ¨ ì‹œ Google)
            featured_image = self.fetch_ai_image(keyword)
            if not featured_image:
                self._log("AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” ê¶Œí•œ ì—†ìŒ. Google ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                featured_image = self.fetch_google_image(keyword)
            
            # 4. ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._get_category_prompt(keyword, category, news_items, news_summary)
            
            self._log(f"Gemini ì½˜í…ì¸  ìƒì„± ì¤‘... (Category: {category})")
            
            # 5. AI ìƒì„±
            response = self.model.generate_content(prompt)
            main_content = response.text
            
            # 6. ì¶”ê°€ ì½˜í…ì¸  fetching
            youtube_embed = self.fetch_youtube_video(keyword)
            related_posts = self.get_related_posts(keyword)
            
            # 7. Markdown ì½˜í…ì¸  ì¡°ë¦½
            markdown_content = self._build_markdown_content(
                keyword, main_content, news_items, featured_image, 
                youtube_embed=youtube_embed, related_posts=related_posts
            )
            
            self._log("ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ")
            return markdown_content
        
        except Exception as e:
            self._log(f"ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            self._log(traceback.format_exc())
            return None
    
    def download_image(self, image_url, keyword, index=0):
        """
        ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¡œì»¬ ì €ì¥
        
        Returns:
            str: ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” ì›ë³¸ URL
        """
        try:
            import requests
            import os
            from urllib.parse import urlparse
            
            # images ë””ë ‰í† ë¦¬ ìƒì„±
            images_dir = os.path.join(self.blog_posts_dir, 'images')
            if not os.path.exists(images_dir):
                os.makedirs(images_dir)
            
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            ext = '.jpg'  # ê¸°ë³¸ í™•ì¥ì
            filename = f"{timestamp}_{keyword}_{index}{ext}"
            filepath = os.path.join(images_dir, filename)
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = requests.get(image_url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            if response.status_code == 200:
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                # ìƒëŒ€ ê²½ë¡œ ë°˜í™˜
                relative_path = f"images/{filename}"
                self._log(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {relative_path}")
                return relative_path
            
        except Exception as e:
            self._log(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return image_url  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ URL ë°˜í™˜
    
    def _build_markdown_content(self, keyword, main_content, news_items, featured_image, youtube_embed=None, related_posts=None):
        """
        Markdown ì½˜í…ì¸  ìƒì„± (Frontmatter í¬í•¨)
        """
        # ëŒ€í‘œ ì´ë¯¸ì§€ ì²˜ë¦¬
        local_featured_image = None
        if featured_image:
            if featured_image.startswith('http'):
                local_featured_image = self.download_image(featured_image, keyword, 'featured')
            else:
                # ì´ë¯¸ ë¡œì»¬ ê²½ë¡œì¸ ê²½ìš° (AI ìƒì„± ë“±)
                local_featured_image = featured_image
        
        # ë‚ ì§œ ìƒì„±
        today = datetime.now().strftime('%Y-%m-%d')
        
        # AIê°€ ìƒì„±í•œ ë³¸ë¬¸ì—ì„œ Frontmatter ì²˜ë¦¬ ë° ëŒ€í‘œ ì´ë¯¸ì§€ ì‚½ì…
        markdown = ""
        
        # Frontmatter ë¶„ë¦¬ (---ë¡œ ì‹œì‘í•˜ê³  ---ë¡œ ëë‚˜ëŠ” ë¶€ë¶„ ì°¾ê¸°)
        if main_content.strip().startswith('---'):
            parts = main_content.split('---', 2)
            if len(parts) >= 3:
                # parts[0]ì€ ë¹ˆ ë¬¸ìì—´, parts[1]ì€ Frontmatter ë‚´ìš©, parts[2]ëŠ” ë³¸ë¬¸
                frontmatter = f"---{parts[1]}---\n\n"
                body = parts[2].strip()
                
                markdown += frontmatter
                
                # ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ê°€ (Frontmatter ì§í›„)
                if local_featured_image:
                    markdown += f"![{keyword}]({local_featured_image})\n\n"
                
                markdown += f"{body}\n\n"
            else:
                # Frontmatter í˜•ì‹ì´ ì´ìƒí•˜ë©´ ê·¸ëƒ¥ í•©ì¹˜ê¸°
                if local_featured_image:
                    markdown += f"![{keyword}]({local_featured_image})\n\n"
                markdown += f"{main_content}\n\n"
        else:
            # Frontmatterê°€ ì—†ëŠ” ê²½ìš° (ë§Œì•½ì„ ëŒ€ë¹„í•´)
            if local_featured_image:
                markdown += f"![{keyword}]({local_featured_image})\n\n"
            markdown += f"{main_content}\n\n"
        
        # YouTube ì„¹ì…˜ ì¶”ê°€
        if youtube_embed:
            markdown += "## ğŸ¬ ê´€ë ¨ ì˜ìƒ\n\n"
            markdown += f"{youtube_embed}\n\n"
            
        # ë‰´ìŠ¤ ì„¹ì…˜ ì¶”ê°€
        if news_items:
            markdown += "## ğŸ“° ê´€ë ¨ ë‰´ìŠ¤\n\n"
            for idx, news in enumerate(news_items):
                # ë‰´ìŠ¤ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                news_image = news.get('image', '')
                if news_image and news_image.startswith('http'):
                    news_image = self.download_image(news_image, keyword, f'news_{idx}')
                
                markdown += f"### [{news['title']}]({news['url']})\n"
                markdown += f"* **ì¶œì²˜**: {news.get('source', 'Unknown Source')}\n"
                if news_image:
                    markdown += f"![ë‰´ìŠ¤ ì´ë¯¸ì§€]({news_image})\n"
                markdown += f"> {news['summary'][:150]}...\n\n"
                
        # ë‚´ë¶€ ë§í¬ ì„¹ì…˜ ì¶”ê°€
        if related_posts:
            markdown += "## ğŸ”— í•¨ê»˜ ë³´ë©´ ì¢‹ì€ ê¸€\n\n"
            for post in related_posts:
                markdown += f"* [{post['title']}](file://{post['filename']})\n"
            markdown += "\n"
            
        return markdown
        
        # ì „ì²´ HTML ë¬¸ì„œ
        html = f'''<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="{keyword}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë‰´ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”. íŠ¸ë Œë“œ ë¶„ì„ê³¼ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.">
    <meta name="keywords" content="{keyword}, íŠ¸ë Œë“œ, ë‰´ìŠ¤, ì •ë³´">
    <meta name="author" content="Trend Blog System">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="{keyword} - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„">
    <meta property="og:description" content="{keyword}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë‰´ìŠ¤">
    {f'<meta property="og:image" content="{featured_image}">' if featured_image else ''}
    
    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="{keyword} - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„">
    <meta name="twitter:description" content="{keyword}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ ë‰´ìŠ¤">
    {f'<meta name="twitter:image" content="{featured_image}">' if featured_image else ''}
    
    <title>{keyword} - ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„</title>
    
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        
        .container {{
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        
        .featured-image {{
            width: 100%;
            max-height: 400px;
            object-fit: cover;
            border-radius: 8px;
            margin-bottom: 30px;
        }}
        
        h1 {{
            color: #1a1a1a;
            font-size: 2.5em;
            margin-bottom: 20px;
            line-height: 1.2;
        }}
        
        h2 {{
            color: #2c3e50;
            font-size: 1.8em;
            margin-top: 30px;
            margin-bottom: 15px;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }}
        
        h3 {{
            color: #34495e;
            font-size: 1.3em;
            margin-top: 20px;
        }}
        
        p {{
            margin-bottom: 15px;
            font-size: 1.1em;
        }}
        
        .news-section {{
            margin: 40px 0;
            padding: 30px;
            background-color: #f8f9fa;
            border-radius: 8px;
        }}
        
        .news-cards {{
            display: grid;
            gap: 20px;
            margin-top: 20px;
        }}
        
        .news-card {{
            display: flex;
            gap: 15px;
            background-color: white;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #3498db;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            transition: transform 0.2s, box-shadow 0.2s;
        }}
        
        .news-card:hover {{
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }}
        
        .news-image {{
            width: 120px;
            height: 120px;
            object-fit: cover;
            border-radius: 4px;
            flex-shrink: 0;
        }}
        
        .news-content {{
            flex: 1;
        }}
        
        .news-content h3 {{
            margin: 0 0 10px 0;
            font-size: 1.1em;
        }}
        
        .news-content h3 a {{
            color: #2c3e50;
            text-decoration: none;
        }}
        
        .news-content h3 a:hover {{
            color: #3498db;
            text-decoration: underline;
        }}
        
        .news-summary {{
            color: #666;
            font-size: 0.95em;
            margin: 0;
        }}
        
        strong {{
            color: #2c3e50;
            font-weight: 600;
        }}
        
        em {{
            color: #7f8c8d;
            font-style: italic;
        }}
        
        @media (max-width: 768px) {{
            .container {{
                padding: 20px;
            }}
            
            h1 {{
                font-size: 2em;
            }}
            
            .news-card {{
                flex-direction: column;
            }}
            
            .news-image {{
                width: 100%;
                height: 200px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        {featured_image_html}
        {news_cards_html}
        {main_content}
    </div>
</body>
</html>'''
        
        return html
    
    def save_blog_post(self, keyword, content):
        """
        ìƒì„±ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥
        
        Args:
            keyword: í‚¤ì›Œë“œ
            content: ë¸”ë¡œê·¸ ì½˜í…ì¸  (HTML)
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{timestamp}_{keyword}.md"
            filepath = os.path.join(self.blog_posts_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self._log(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            
            # ì‚¬ìš©ëœ í‚¤ì›Œë“œ ëª©ë¡ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
            used_keywords = self._load_used_keywords()
            if keyword not in used_keywords:
                used_keywords.append(keyword)
                self._save_used_keywords(used_keywords)
            
            return filepath
        
        except Exception as e:
            self._log(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            return None
    
    def run_blog_creation(self):
        """
        ì „ì²´ ë¸”ë¡œê·¸ ì‘ì„± í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        """
        self._log("=" * 50)
        self._log("ë¸”ë¡œê·¸ ì‘ì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        
        # 1. íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        keywords = self.get_trending_keywords()
        
        if not keywords:
            self._log("í‚¤ì›Œë“œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ì„ íƒ
        selected_keyword = self.select_keyword(keywords)
        
        if not selected_keyword:
            self._log("ëª¨ë“  í‚¤ì›Œë“œê°€ ì´ë¯¸ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        # 3. ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„±
        content = self.generate_blog_content(selected_keyword)
        
        if not content:
            self._log("ì½˜í…ì¸  ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # 4. ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì €ì¥
        filepath = self.save_blog_post(selected_keyword, content)
        
        if filepath:
            self._log(f"ë¸”ë¡œê·¸ ì‘ì„± ì™„ë£Œ: {selected_keyword}")
            self._send_telegram_notification(f"âœ… *ë¸”ë¡œê·¸ ìƒì„± ì™„ë£Œ*\n\n*í‚¤ì›Œë“œ*: {selected_keyword}\n*íŒŒì¼*: `{os.path.basename(filepath)}`")
        else:
            self._log("ë¸”ë¡œê·¸ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            self._send_telegram_notification(f"âŒ *ë¸”ë¡œê·¸ ìƒì„± ì‹¤íŒ¨*\n\n*í‚¤ì›Œë“œ*: {selected_keyword}\n*ì›ì¸*: íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
        
        self._log("ë¸”ë¡œê·¸ ì‘ì„± í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
        self._log("=" * 50)

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
    """
    system = TrendBlogSystem()
    
    # ì„¤ì •ì—ì„œ ë°œí–‰ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    publication_times = system.config.get('publication_times', ["08:00", "12:00", "16:00", "20:00"])
    
    # ìŠ¤ì¼€ì¤„ ì„¤ì •
    for t in publication_times:
        try:
            schedule.every().day.at(t).do(system.run_blog_creation)
        except Exception as e:
            print(f"ìŠ¤ì¼€ì¤„ ì„¤ì • ì˜¤ë¥˜ ({t}): {e}")
    
    print("ë¸”ë¡œê·¸ ìë™ ì‘ì„± ì‹œìŠ¤í…œ ì‹œì‘")
    print(f"ìŠ¤ì¼€ì¤„: {', '.join(publication_times)}")
    print("ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    
    # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
    # system.run_blog_creation()
    
    # ìŠ¤ì¼€ì¤„ ë£¨í”„ ì‹¤í–‰
    while True:
        schedule.run_pending()
        time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬

if __name__ == "__main__":
    main()